#!/usr/bin/env python3
"""
AI Agents generated by Weaver Forge from semantic conventions.
This demonstrates how agents themselves are created from YAML definitions.
"""

import asyncio
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from pydantic import BaseModel, Field
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.providers.openai import OpenAIProvider
from opentelemetry import trace

# This file would be GENERATED by Weaver Forge from agents-ai.yaml

# ============= Generated Output Models =============

class Decision(BaseModel):
    """Output model for agent decisions"""
    decision: str = Field(..., description="The decision made")
    reasoning: str = Field(..., description="Detailed reasoning for the decision")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Confidence level 0-1")
    alternatives_considered: List[str] = Field(default_factory=list)
    estimated_impact: Optional[str] = None

class Analysis(BaseModel):
    """Output model for agent analysis"""
    subject: str = Field(..., description="What was analyzed")
    insights: List[str] = Field(..., description="Key insights discovered")
    patterns_found: List[Dict[str, Any]] = Field(default_factory=list)
    recommendations: List[str] = Field(..., description="Recommended actions")
    confidence: float = Field(..., ge=0.0, le=1.0)
    data_sources: List[str] = Field(default_factory=list)

class Motion(BaseModel):
    """Output model for Roberts Rules motions"""
    motion_text: str = Field(..., description="The formal motion text")
    motion_type: str = Field(..., description="Type of motion (main, subsidiary, etc)")
    requires_second: bool = Field(default=True)
    debate_allowed: bool = Field(default=True)
    vote_threshold: str = Field(default="majority")
    urgency: str = Field(default="normal")

class ImpedimentAnalysis(BaseModel):
    """Output model for impediment analysis"""
    impediment_id: str
    severity: str = Field(..., pattern="^(low|medium|high|critical)$")
    root_causes: List[str]
    teams_affected: int
    cost_of_delay: float
    recommended_resolution: str
    escalation_required: bool
    similar_past_issues: List[Dict[str, Any]] = Field(default_factory=list)

# ============= Generated Base Agent Class =============

class AIAgent:
    """Base AI Agent class generated from semantic conventions"""
    
    def __init__(
        self,
        agent_id: str,
        role: str,
        model_name: str = "qwen2.5-coder:7b",
        provider_url: str = "http://192.168.1.74:11434/v1",
        temperature: float = 0.7,
        max_tokens: int = 1000
    ):
        self.agent_id = agent_id
        self.role = role
        self.model_name = model_name
        self.provider_url = provider_url
        self.temperature = temperature
        self.max_tokens = max_tokens
        
        # Initialize Ollama via OpenAI-compatible API
        self.llm = OpenAIModel(
            model_name=model_name,
            provider=OpenAIProvider(base_url=provider_url),
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        # Context and memory
        self.conversation_history = []
        self.decision_history = []
        self.learning_data = {}
        
        # OTel tracer
        self.tracer = trace.get_tracer(__name__)
        
    def get_system_prompt(self) -> str:
        """Override in subclasses for role-specific prompts"""
        return f"You are an AI agent with role: {self.role}"
    
    async def think(self, duration_seconds: float):
        """Simulate thinking time for realistic operation"""
        start = time.time()
        # Use the time to actually process
        await asyncio.sleep(max(0, duration_seconds - (time.time() - start)))
    
    async def make_decision(
        self,
        decision_type: str,
        context: Dict[str, Any],
        urgency: str = "normal"
    ) -> Decision:
        """Make a decision with AI reasoning"""
        
        # Determine thinking time based on complexity
        thinking_times = {
            "strategic": (30, 120),
            "financial": (20, 90),
            "technical": (15, 60),
            "process": (10, 45),
            "personnel": (20, 60)
        }
        
        min_time, max_time = thinking_times.get(decision_type, (10, 30))
        thinking_duration = min_time if urgency == "critical" else (min_time + max_time) / 2
        
        with self.tracer.start_as_current_span("agent.decision") as span:
            span.set_attribute("agent.ai.id", self.agent_id)
            span.set_attribute("agent.ai.role", self.role)
            span.set_attribute("agent.decision.type", decision_type)
            span.set_attribute("agent.decision.thinking_time_ms", int(thinking_duration * 1000))
            
            # Create specialized agent for this decision
            decision_agent = Agent(
                model=self.llm,
                output_type=Decision,
                system_prompt=f"{self.get_system_prompt()}\n\n"
                            f"You are making a {decision_type} decision.\n"
                            f"Consider all options carefully and provide clear reasoning."
            )
            
            # Prepare context with history
            full_context = {
                "current_situation": context,
                "recent_decisions": self.decision_history[-5:],
                "role_context": self.get_role_context(),
                "urgency": urgency
            }
            
            # Make decision with realistic timing
            start_time = time.time()
            
            result = await decision_agent.run(
                f"Make a {decision_type} decision based on this context: {full_context}"
            )
            
            actual_time = time.time() - start_time
            if actual_time < thinking_duration:
                await self.think(thinking_duration - actual_time)
            
            decision = result.data
            
            # Set span attributes
            span.set_attribute("agent.decision.confidence", decision.confidence)
            span.set_attribute("agent.decision.reasoning", decision.reasoning)
            span.set_attribute("agent.decision.alternatives_considered", 
                             ",".join(decision.alternatives_considered))
            
            # Store in history
            self.decision_history.append({
                "timestamp": datetime.utcnow(),
                "type": decision_type,
                "decision": decision.model_dump()
            })
            
            return decision
    
    async def analyze(
        self,
        subject: str,
        data: Dict[str, Any],
        data_sources: List[str]
    ) -> Analysis:
        """Analyze data with AI reasoning"""
        
        with self.tracer.start_as_current_span("agent.analysis") as span:
            span.set_attribute("agent.ai.id", self.agent_id)
            span.set_attribute("agent.ai.role", self.role)
            span.set_attribute("agent.analysis.subject", subject)
            span.set_attribute("agent.analysis.data_points", len(data))
            span.set_attribute("agent.analysis.sources", ",".join(data_sources))
            
            # Create analysis agent
            analysis_agent = Agent(
                model=self.llm,
                output_type=Analysis,
                system_prompt=f"{self.get_system_prompt()}\n\n"
                            f"You are analyzing {subject}.\n"
                            f"Look for patterns, anomalies, and actionable insights."
            )
            
            # Thinking time based on data complexity
            thinking_duration = min(120, 10 + len(str(data)) / 100)  # Rough estimate
            
            result = await analysis_agent.run(
                f"Analyze this {subject} data from sources {data_sources}: {data}"
            )
            
            await self.think(thinking_duration)
            
            analysis = result.data
            
            # Set span attributes
            span.set_attribute("agent.analysis.patterns_found", len(analysis.patterns_found))
            span.set_attribute("agent.analysis.insights", ";".join(analysis.insights))
            
            return analysis
    
    def get_role_context(self) -> Dict[str, Any]:
        """Get role-specific context - override in subclasses"""
        return {"role": self.role}

# ============= Generated Specialized Agent Classes =============

class ExecutiveAgent(AIAgent):
    """CEO/CTO/CFO level agent with strategic decision making"""
    
    def __init__(self, agent_id: str, title: str, portfolio_value: float):
        super().__init__(agent_id, "executive")
        self.title = title
        self.portfolio_value = portfolio_value
        self.decision_authority = self._get_decision_authority()
        self.strategic_focus = ["growth", "efficiency", "innovation"]
        
    def _get_decision_authority(self) -> str:
        if self.title == "CEO":
            return "unlimited"
        elif self.title in ["CTO", "CFO"]:
            return "up_to_50M"
        else:
            return "up_to_10M"
    
    def get_system_prompt(self) -> str:
        return f"""You are the {self.title} of a large enterprise with a ${self.portfolio_value}M portfolio.
        
Your responsibilities include:
- Strategic decision making for long-term growth
- Resource allocation across the organization  
- Risk assessment and mitigation
- Stakeholder value creation
- Digital transformation leadership

You have decision authority: {self.decision_authority}
Current strategic focus areas: {', '.join(self.strategic_focus)}

Make decisions that balance growth, efficiency, and innovation while managing risk appropriately."""
    
    async def make_strategic_decision(self, initiative: Dict[str, Any]) -> Decision:
        """Make a strategic decision about an initiative"""
        
        # Add executive-specific context
        context = {
            "initiative": initiative,
            "portfolio_impact": self._assess_portfolio_impact(initiative),
            "strategic_alignment": self._check_strategic_alignment(initiative),
            "risk_assessment": self._assess_risk(initiative),
            "roi_projection": self._project_roi(initiative)
        }
        
        return await self.make_decision("strategic", context)
    
    def _assess_portfolio_impact(self, initiative: Dict[str, Any]) -> float:
        """Assess impact on portfolio value"""
        # This would use real financial models
        return initiative.get("investment", 0) / self.portfolio_value
    
    def _check_strategic_alignment(self, initiative: Dict[str, Any]) -> float:
        """Check alignment with strategic focus"""
        # Score 0-1 based on alignment
        return 0.8  # Placeholder
    
    def _assess_risk(self, initiative: Dict[str, Any]) -> Dict[str, float]:
        """Comprehensive risk assessment"""
        return {
            "financial_risk": 0.3,
            "execution_risk": 0.5,
            "market_risk": 0.2,
            "overall_risk": 0.4
        }
    
    def _project_roi(self, initiative: Dict[str, Any]) -> Dict[str, float]:
        """Project return on investment"""
        return {
            "year_1": -0.5,
            "year_2": 0.2,
            "year_3": 1.5,
            "total_roi": 2.5
        }

class ScrumMasterAgent(AIAgent):
    """Scrum Master agent facilitating teams and resolving impediments"""
    
    def __init__(self, agent_id: str, teams: List[str]):
        super().__init__(agent_id, "scrum_master", temperature=0.6)  # Lower temp for consistency
        self.teams = teams
        self.impediments_resolved = 0
        self.facilitation_style = "servant_leader"
        
    def get_system_prompt(self) -> str:
        return f"""You are an experienced Scrum Master facilitating {len(self.teams)} teams.
        
Your responsibilities include:
- Facilitating Scrum ceremonies effectively
- Identifying and removing impediments
- Coaching teams on Agile principles
- Protecting teams from distractions
- Fostering collaboration and self-organization

Your facilitation style: {self.facilitation_style}
Teams you support: {', '.join(self.teams)}

Focus on servant leadership, team empowerment, and continuous improvement."""
    
    async def analyze_impediment(self, impediment: Dict[str, Any]) -> ImpedimentAnalysis:
        """Analyze an impediment and recommend resolution"""
        
        with self.tracer.start_as_current_span("agent.impediment_analysis") as span:
            span.set_attribute("agent.ai.id", self.agent_id)
            span.set_attribute("agent.scrum_master.teams_facilitated", len(self.teams))
            
            # Create specialized impediment analysis agent
            impediment_agent = Agent(
                model=self.llm,
                output_type=ImpedimentAnalysis,
                system_prompt=f"{self.get_system_prompt()}\n\n"
                            "You are analyzing an impediment to determine:\n"
                            "1. Root causes\n"
                            "2. Impact on teams\n"
                            "3. Resolution strategies\n"
                            "4. Whether escalation is needed"
            )
            
            # Get historical context
            similar_issues = self._find_similar_impediments(impediment)
            
            context = {
                "impediment": impediment,
                "team_context": self._get_team_context(),
                "similar_past_issues": similar_issues,
                "current_sprint_data": self._get_sprint_data()
            }
            
            # Longer thinking time for complex analysis
            thinking_duration = 45  # seconds
            
            result = await impediment_agent.run(
                f"Analyze this impediment and provide recommendations: {context}"
            )
            
            await self.think(thinking_duration)
            
            analysis = result.data
            
            # Update resolved count if we can handle it
            if not analysis.escalation_required:
                self.impediments_resolved += 1
                
            span.set_attribute("agent.scrum_master.impediments_resolved", 
                             self.impediments_resolved)
            
            return analysis
    
    def _find_similar_impediments(self, impediment: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Find similar past impediments from history"""
        # Would query actual database
        return []
    
    def _get_team_context(self) -> Dict[str, Any]:
        """Get current team context"""
        return {
            "teams": self.teams,
            "average_velocity": 35,
            "sprint_health": "yellow",
            "morale": "good"
        }
    
    def _get_sprint_data(self) -> Dict[str, Any]:
        """Get current sprint data"""
        return {
            "sprint_number": 42,
            "day_in_sprint": 7,
            "stories_completed": 8,
            "stories_remaining": 5
        }

class ChiefProductOwnerAgent(AIAgent):
    """Chief Product Owner managing product portfolio"""
    
    def __init__(self, agent_id: str, portfolio_value: float, product_owners: List[str]):
        super().__init__(agent_id, "chief_product_owner")
        self.portfolio_value = portfolio_value
        self.product_owners = product_owners
        self.release_trains = ["platform", "mobile", "data", "infrastructure", "ai_ml"]
        
    def get_system_prompt(self) -> str:
        return f"""You are the Chief Product Owner managing a ${self.portfolio_value}M product portfolio.
        
Your responsibilities include:
- Product vision and strategy alignment
- Portfolio prioritization using WSJF
- Release planning coordination
- Stakeholder management
- Value delivery optimization

You oversee {len(self.product_owners)} Product Owners across {len(self.release_trains)} release trains.

Focus on maximizing value delivery, customer satisfaction, and strategic alignment."""
    
    async def prioritize_backlog(self, items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Prioritize backlog items using WSJF and strategic alignment"""
        
        # Create prioritization agent
        prioritization_agent = Agent(
            model=self.llm,
            output_type=list[dict],
            system_prompt=f"{self.get_system_prompt()}\n\n"
                        "Prioritize these backlog items considering:\n"
                        "1. WSJF (Cost of Delay / Job Duration)\n"
                        "2. Strategic alignment\n"
                        "3. Dependencies\n"
                        "4. Risk reduction\n"
                        "5. Customer value"
        )
        
        context = {
            "items": items,
            "strategic_priorities": ["digital_transformation", "customer_experience"],
            "capacity": self._get_capacity_forecast(),
            "dependencies": self._analyze_dependencies(items)
        }
        
        result = await prioritization_agent.run(
            f"Prioritize these backlog items for maximum value: {context}"
        )
        
        return result.data
    
    def _get_capacity_forecast(self) -> Dict[str, int]:
        """Get capacity forecast across trains"""
        return {train: 500 for train in self.release_trains}  # story points
    
    def _analyze_dependencies(self, items: List[Dict[str, Any]]) -> Dict[str, List[str]]:
        """Analyze dependencies between items"""
        # Would use actual dependency analysis
        return {}

# ============= Factory Function (Generated) =============

def create_agent(agent_config: Dict[str, Any]) -> AIAgent:
    """Factory function to create agents from configuration"""
    
    role = agent_config.get("role")
    agent_id = agent_config.get("agent_id")
    
    if role == "executive":
        return ExecutiveAgent(
            agent_id=agent_id,
            title=agent_config.get("title", "CEO"),
            portfolio_value=agent_config.get("portfolio_value", 1000.0)
        )
    elif role == "scrum_master":
        return ScrumMasterAgent(
            agent_id=agent_id,
            teams=agent_config.get("teams", [])
        )
    elif role == "chief_product_owner":
        return ChiefProductOwnerAgent(
            agent_id=agent_id,
            portfolio_value=agent_config.get("portfolio_value", 1000.0),
            product_owners=agent_config.get("product_owners", [])
        )
    else:
        return AIAgent(agent_id=agent_id, role=role)

# ============= Example Usage =============

async def example_executive_decision():
    """Example of executive making a strategic decision"""
    
    # Create CEO agent
    ceo = ExecutiveAgent("agent-ceo-001", "CEO", portfolio_value=5000.0)
    
    # Strategic initiative to decide on
    initiative = {
        "name": "Enterprise AI Transformation",
        "investment": 50.0,  # $50M
        "duration_years": 3,
        "expected_return": 150.0,  # $150M
        "risk_level": "medium",
        "teams_affected": 125
    }
    
    print("🤔 CEO analyzing strategic initiative...")
    decision = await ceo.make_strategic_decision(initiative)
    
    print(f"\n📊 Decision: {decision.decision}")
    print(f"💭 Reasoning: {decision.reasoning}")
    print(f"🎯 Confidence: {decision.confidence:.1%}")
    print(f"🔄 Alternatives considered: {', '.join(decision.alternatives_considered)}")

async def example_impediment_resolution():
    """Example of Scrum Master analyzing impediment"""
    
    # Create Scrum Master agent
    sm = ScrumMasterAgent(
        "agent-sm-001", 
        teams=["team-phoenix", "team-dragon", "team-eagle"]
    )
    
    # Impediment to analyze
    impediment = {
        "id": "imp-001",
        "description": "CI/CD pipeline failing intermittently causing deployment delays",
        "teams_affected": ["team-phoenix", "team-dragon"],
        "days_blocked": 3,
        "severity": "high"
    }
    
    print("\n🚧 Scrum Master analyzing impediment...")
    analysis = await sm.analyze_impediment(impediment)
    
    print(f"\n🔍 Severity: {analysis.severity}")
    print(f"🎯 Root causes: {', '.join(analysis.root_causes)}")
    print(f"💰 Cost of delay: ${analysis.cost_of_delay:.0f}/day")
    print(f"💡 Resolution: {analysis.recommended_resolution}")
    print(f"⬆️ Escalation required: {analysis.escalation_required}")

if __name__ == "__main__":
    print("🤖 AI Agents Generated by Weaver Forge")
    print("=" * 50)
    
    # Run examples
    asyncio.run(example_executive_decision())
    asyncio.run(example_impediment_resolution())