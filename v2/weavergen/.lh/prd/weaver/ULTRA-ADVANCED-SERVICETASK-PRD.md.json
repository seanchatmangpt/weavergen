{
    "sourceFile": "prd/weaver/ULTRA-ADVANCED-SERVICETASK-PRD.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1751483586033,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1751483586033,
            "name": "Commit-0",
            "content": "# Ultra-Advanced Base ServiceTask PRD\n\n## Executive Summary\n\nThis PRD defines the requirements for an ultra-advanced, elegant base ServiceTask class that provides automatic OpenTelemetry instrumentation, intelligent filepath tracking, performance monitoring, and sophisticated error handling. This base class will serve as the foundation for all service tasks in the WeaverGen BPMN workflow system, ensuring consistent observability, maintainability, and developer experience.\n\n## Mission Statement\n\n**Create an intelligent, self-instrumenting base ServiceTask that automatically captures context, performance metrics, and operational insights while providing an elegant, developer-friendly interface for implementing business logic in BPMN workflows.**\n\n## Core Vision\n\nTransform service task development from manual instrumentation and boilerplate code to an elegant, declarative experience where developers focus on business logic while the framework automatically handles observability, performance monitoring, and operational excellence.\n\n## Target Users\n\n### Primary Users\n- **BPMN Workflow Developers**: Engineers implementing service tasks for business processes\n- **DevOps Engineers**: Teams monitoring and maintaining workflow performance\n- **SRE Teams**: Site reliability engineers managing production workflows\n\n### Secondary Users\n- **AI Code Assistants**: AI tools that generate service task implementations\n- **Code Reviewers**: Engineers reviewing service task implementations\n- **Platform Architects**: Engineers designing workflow patterns and standards\n\n## Key Requirements\n\n### 1. Automatic OpenTelemetry Instrumentation\n\n#### 1.1 Context-Aware Span Creation\n- **Automatic span naming**: Generate meaningful span names from class and method names\n- **Context inheritance**: Automatically inherit parent span context from workflow\n- **Span attributes**: Auto-populate common attributes (class, method, workflow_id, etc.)\n- **Custom attributes**: Support for declarative attribute definition\n\n#### 1.2 Filepath and Resource Tracking\n- **Automatic filepath detection**: Detect and track file operations from method parameters\n- **Resource monitoring**: Track file sizes, modification times, and access patterns\n- **Dependency tracking**: Automatically identify and track external dependencies\n- **I/O metrics**: Capture read/write operations, file counts, and data volumes\n\n#### 1.3 Performance Metrics\n- **Execution timing**: Automatic duration tracking with percentile analysis\n- **Memory usage**: Track memory allocation and garbage collection patterns\n- **CPU utilization**: Monitor CPU usage during task execution\n- **Resource consumption**: Track disk I/O, network calls, and external API usage\n\n### 2. Intelligent Error Handling\n\n#### 2.1 Contextual Error Capture\n- **Error classification**: Automatically categorize errors (validation, I/O, network, etc.)\n- **Error context**: Capture relevant context at error time (input data, file paths, etc.)\n- **Error correlation**: Link errors to specific workflow instances and data\n- **Recovery suggestions**: Provide intelligent recovery recommendations\n\n#### 2.2 Graceful Degradation\n- **Retry mechanisms**: Intelligent retry with exponential backoff\n- **Circuit breaker**: Automatic circuit breaker for external dependencies\n- **Fallback strategies**: Configurable fallback mechanisms\n- **Error propagation**: Proper error propagation through workflow hierarchy\n\n### 3. Elegant Developer Experience\n\n#### 3.1 Declarative Configuration\n- **Decorator-based configuration**: Use decorators for task configuration\n- **Type hints integration**: Full type hint support with runtime validation\n- **Configuration inheritance**: Inherit configuration from base classes\n- **Environment-aware**: Automatic configuration based on environment\n\n#### 3.2 Intuitive API Design\n- **Fluent interface**: Chainable method calls for complex operations\n- **Context managers**: Elegant context management for resource handling\n- **Async support**: Native async/await support for I/O operations\n- **Batch operations**: Support for batch processing with progress tracking\n\n### 4. Advanced Monitoring and Analytics\n\n#### 4.1 Real-time Metrics\n- **Custom metrics**: Support for custom business metrics\n- **Histograms**: Automatic histogram creation for performance data\n- **Counters**: Track operation counts and success/failure rates\n- **Gauges**: Monitor resource usage and system state\n\n#### 4.2 Predictive Analytics\n- **Performance prediction**: Predict execution time based on input size\n- **Resource forecasting**: Forecast resource requirements\n- **Anomaly detection**: Detect performance anomalies and unusual patterns\n- **Trend analysis**: Analyze performance trends over time\n\n## Technical Architecture\n\n### 1. Base ServiceTask Class Design\n\n```python\n@dataclass\nclass ServiceTaskConfig:\n    \"\"\"Configuration for service task behavior.\"\"\"\n    name: str\n    description: str = \"\"\n    timeout: Optional[float] = None\n    retry_count: int = 3\n    retry_backoff: float = 1.5\n    circuit_breaker_threshold: int = 5\n    circuit_breaker_timeout: float = 60.0\n    enable_performance_tracking: bool = True\n    enable_file_tracking: bool = True\n    enable_memory_tracking: bool = True\n    custom_attributes: Dict[str, Any] = field(default_factory=dict)\n    custom_metrics: List[str] = field(default_factory=list)\n\n\nclass UltraAdvancedServiceTask:\n    \"\"\"Ultra-advanced base class for all service tasks.\"\"\"\n    \n    def __init__(self, config: ServiceTaskConfig):\n        self.config = config\n        self._tracer = trace.get_tracer(self.__class__.__name__)\n        self._metrics = self._setup_metrics()\n        self._circuit_breaker = self._setup_circuit_breaker()\n        self._file_tracker = self._setup_file_tracker()\n        self._performance_tracker = self._setup_performance_tracker()\n    \n    @contextmanager\n    def task_span(self, operation_name: str, **attributes):\n        \"\"\"Create a task span with automatic context and attributes.\"\"\"\n        with self._tracer.start_as_current_span(\n            f\"{self.config.name}.{operation_name}\",\n            attributes=self._build_span_attributes(attributes)\n        ) as span:\n            try:\n                # Auto-detect file operations\n                self._file_tracker.start_tracking(span)\n                \n                # Start performance monitoring\n                self._performance_tracker.start_monitoring(span)\n                \n                yield span\n                \n                # Record success metrics\n                self._record_success_metrics(span)\n                \n            except Exception as e:\n                # Record error metrics and context\n                self._record_error_metrics(span, e)\n                raise\n    \n    def execute_with_retry(self, operation: Callable, *args, **kwargs):\n        \"\"\"Execute operation with intelligent retry logic.\"\"\"\n        for attempt in range(self.config.retry_count + 1):\n            try:\n                with self.task_span(\"execute_with_retry\") as span:\n                    span.set_attribute(\"retry.attempt\", attempt)\n                    \n                    # Check circuit breaker\n                    if self._circuit_breaker.is_open():\n                        raise CircuitBreakerOpenError(\"Circuit breaker is open\")\n                    \n                    result = operation(*args, **kwargs)\n                    \n                    # Record success\n                    self._circuit_breaker.record_success()\n                    return result\n                    \n            except Exception as e:\n                self._circuit_breaker.record_failure()\n                \n                if attempt == self.config.retry_count:\n                    raise\n                \n                # Exponential backoff\n                wait_time = self.config.retry_backoff ** attempt\n                time.sleep(wait_time)\n    \n    def track_file_operations(self, file_paths: List[Path]):\n        \"\"\"Track file operations with automatic metrics.\"\"\"\n        with self.task_span(\"track_file_operations\") as span:\n            for file_path in file_paths:\n                if file_path.exists():\n                    stat = file_path.stat()\n                    span.set_attribute(f\"file.{file_path.name}.size\", stat.st_size)\n                    span.set_attribute(f\"file.{file_path.name}.modified\", stat.st_mtime)\n                    span.set_attribute(f\"file.{file_path.name}.permissions\", oct(stat.st_mode))\n    \n    def measure_performance(self, operation_name: str):\n        \"\"\"Decorator for measuring operation performance.\"\"\"\n        def decorator(func):\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n                with self.task_span(f\"measure_performance.{operation_name}\") as span:\n                    start_time = time.perf_counter()\n                    start_memory = psutil.Process().memory_info().rss\n                    \n                    try:\n                        result = func(*args, **kwargs)\n                        \n                        # Record performance metrics\n                        duration = time.perf_counter() - start_time\n                        memory_used = psutil.Process().memory_info().rss - start_memory\n                        \n                        span.set_attribute(\"performance.duration_ms\", duration * 1000)\n                        span.set_attribute(\"performance.memory_bytes\", memory_used)\n                        \n                        return result\n                        \n                    except Exception as e:\n                        span.record_exception(e)\n                        raise\n            \n            return wrapper\n        return decorator\n```\n\n### 2. File Tracking System\n\n```python\nclass IntelligentFileTracker:\n    \"\"\"Intelligent file operation tracking and analysis.\"\"\"\n    \n    def __init__(self):\n        self._file_cache = {}\n        self._operation_history = []\n    \n    def start_tracking(self, span):\n        \"\"\"Start tracking file operations for a span.\"\"\"\n        self._current_span = span\n        self._current_operations = []\n    \n    def track_file_read(self, file_path: Path, content_length: int = None):\n        \"\"\"Track file read operations.\"\"\"\n        operation = {\n            'type': 'read',\n            'path': str(file_path),\n            'size': content_length or file_path.stat().st_size if file_path.exists() else 0,\n            'timestamp': time.time()\n        }\n        self._current_operations.append(operation)\n        \n        # Add to span attributes\n        self._current_span.set_attribute(f\"file.read.{file_path.name}\", operation['size'])\n    \n    def track_file_write(self, file_path: Path, content_length: int = None):\n        \"\"\"Track file write operations.\"\"\"\n        operation = {\n            'type': 'write',\n            'path': str(file_path),\n            'size': content_length or 0,\n            'timestamp': time.time()\n        }\n        self._current_operations.append(operation)\n        \n        # Add to span attributes\n        self._current_span.set_attribute(f\"file.write.{file_path.name}\", operation['size'])\n    \n    def analyze_file_patterns(self):\n        \"\"\"Analyze file operation patterns for optimization.\"\"\"\n        patterns = {\n            'read_heavy': [],\n            'write_heavy': [],\n            'large_files': [],\n            'frequent_access': []\n        }\n        \n        for operation in self._operation_history:\n            if operation['size'] > 1024 * 1024:  # 1MB\n                patterns['large_files'].append(operation['path'])\n            \n            # Analyze access patterns\n            access_count = sum(1 for op in self._operation_history \n                             if op['path'] == operation['path'])\n            if access_count > 10:\n                patterns['frequent_access'].append(operation['path'])\n        \n        return patterns\n```\n\n### 3. Performance Tracking System\n\n```python\nclass AdvancedPerformanceTracker:\n    \"\"\"Advanced performance tracking and analysis.\"\"\"\n    \n    def __init__(self):\n        self._metrics = {}\n        self._baselines = {}\n        self._anomaly_detector = self._setup_anomaly_detector()\n    \n    def start_monitoring(self, span):\n        \"\"\"Start performance monitoring for a span.\"\"\"\n        self._current_span = span\n        self._start_time = time.perf_counter()\n        self._start_memory = psutil.Process().memory_info()\n        self._start_cpu = psutil.Process().cpu_percent()\n    \n    def end_monitoring(self):\n        \"\"\"End performance monitoring and record metrics.\"\"\"\n        duration = time.perf_counter() - self._start_time\n        end_memory = psutil.Process().memory_info()\n        end_cpu = psutil.Process().cpu_percent()\n        \n        # Calculate metrics\n        memory_delta = end_memory.rss - self._start_memory.rss\n        cpu_usage = (end_cpu + self._start_cpu) / 2\n        \n        # Record metrics\n        self._current_span.set_attribute(\"performance.duration_ms\", duration * 1000)\n        self._current_span.set_attribute(\"performance.memory_delta_bytes\", memory_delta)\n        self._current_span.set_attribute(\"performance.cpu_percent\", cpu_usage)\n        \n        # Check for anomalies\n        self._check_performance_anomalies(duration, memory_delta, cpu_usage)\n    \n    def _check_performance_anomalies(self, duration, memory_delta, cpu_usage):\n        \"\"\"Check for performance anomalies.\"\"\"\n        operation_name = self._current_span.name\n        \n        if operation_name not in self._baselines:\n            self._baselines[operation_name] = {\n                'duration': duration,\n                'memory': memory_delta,\n                'cpu': cpu_usage\n            }\n            return\n        \n        baseline = self._baselines[operation_name]\n        \n        # Check for significant deviations\n        duration_ratio = duration / baseline['duration']\n        memory_ratio = memory_delta / baseline['memory'] if baseline['memory'] != 0 else 1\n        \n        if duration_ratio > 2.0 or memory_ratio > 2.0:\n            self._current_span.add_event(\"performance.anomaly_detected\", {\n                \"duration_ratio\": duration_ratio,\n                \"memory_ratio\": memory_ratio,\n                \"baseline_duration\": baseline['duration'],\n                \"baseline_memory\": baseline['memory']\n            })\n```\n\n### 4. Circuit Breaker Implementation\n\n```python\nclass IntelligentCircuitBreaker:\n    \"\"\"Intelligent circuit breaker with adaptive thresholds.\"\"\"\n    \n    def __init__(self, threshold: int, timeout: float):\n        self.threshold = threshold\n        self.timeout = timeout\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n    \n    def is_open(self) -> bool:\n        \"\"\"Check if circuit breaker is open.\"\"\"\n        if self.state == \"OPEN\":\n            if time.time() - self.last_failure_time > self.timeout:\n                self.state = \"HALF_OPEN\"\n                return False\n            return True\n        return False\n    \n    def record_success(self):\n        \"\"\"Record a successful operation.\"\"\"\n        if self.state == \"HALF_OPEN\":\n            self.state = \"CLOSED\"\n            self.failure_count = 0\n    \n    def record_failure(self):\n        \"\"\"Record a failed operation.\"\"\"\n        self.failure_count += 1\n        self.last_failure_time = time.time()\n        \n        if self.failure_count >= self.threshold:\n            self.state = \"OPEN\"\n```\n\n## Usage Examples\n\n### 1. Basic Service Task Implementation\n\n```python\nclass FileProcessingTask(UltraAdvancedServiceTask):\n    \"\"\"Example file processing service task.\"\"\"\n    \n    def __init__(self):\n        config = ServiceTaskConfig(\n            name=\"file_processing\",\n            description=\"Process files with automatic tracking\",\n            timeout=30.0,\n            retry_count=3,\n            enable_file_tracking=True,\n            enable_performance_tracking=True\n        )\n        super().__init__(config)\n    \n    @measure_performance(\"process_files\")\n    def process_files(self, input_files: List[Path], output_dir: Path):\n        \"\"\"Process files with automatic instrumentation.\"\"\"\n        with self.task_span(\"process_files\") as span:\n            # Track input files\n            self.track_file_operations(input_files)\n            \n            # Process files\n            results = []\n            for file_path in input_files:\n                result = self.execute_with_retry(\n                    self._process_single_file, file_path, output_dir\n                )\n                results.append(result)\n            \n            # Track output directory\n            self.track_file_operations([output_dir])\n            \n            span.set_attribute(\"files.processed\", len(results))\n            return results\n    \n    def _process_single_file(self, file_path: Path, output_dir: Path):\n        \"\"\"Process a single file.\"\"\"\n        with self.task_span(\"process_single_file\") as span:\n            span.set_attribute(\"input_file\", str(file_path))\n            span.set_attribute(\"output_dir\", str(output_dir))\n            \n            # File processing logic here\n            output_file = output_dir / f\"processed_{file_path.name}\"\n            # ... processing logic ...\n            \n            return str(output_file)\n```\n\n### 2. Advanced Service Task with Custom Metrics\n\n```python\nclass DataAnalysisTask(UltraAdvancedServiceTask):\n    \"\"\"Advanced data analysis service task.\"\"\"\n    \n    def __init__(self):\n        config = ServiceTaskConfig(\n            name=\"data_analysis\",\n            description=\"Analyze data with custom metrics\",\n            custom_metrics=[\"data_quality_score\", \"processing_efficiency\"],\n            custom_attributes={\n                \"analysis_type\": \"statistical\",\n                \"data_source\": \"database\"\n            }\n        )\n        super().__init__(config)\n    \n    def analyze_dataset(self, dataset_path: Path, analysis_config: Dict):\n        \"\"\"Analyze dataset with advanced tracking.\"\"\"\n        with self.task_span(\"analyze_dataset\") as span:\n            # Track dataset file\n            self.track_file_operations([dataset_path])\n            \n            # Custom metrics\n            quality_score = self._calculate_quality_score(dataset_path)\n            efficiency = self._calculate_efficiency(analysis_config)\n            \n            span.set_attribute(\"custom.data_quality_score\", quality_score)\n            span.set_attribute(\"custom.processing_efficiency\", efficiency)\n            \n            # Analysis logic\n            results = self.execute_with_retry(\n                self._perform_analysis, dataset_path, analysis_config\n            )\n            \n            return results\n```\n\n## Success Metrics\n\n### 1. Developer Experience Metrics\n- **Time to implement**: Reduce service task implementation time by 70%\n- **Code reduction**: Reduce boilerplate code by 80%\n- **Error reduction**: Reduce instrumentation errors by 90%\n- **Developer satisfaction**: Achieve 4.5+ rating on developer experience surveys\n\n### 2. Observability Metrics\n- **Span coverage**: Achieve 100% span coverage for all service tasks\n- **Attribute completeness**: Ensure 95% of spans have relevant attributes\n- **Error tracking**: Capture 100% of errors with full context\n- **Performance visibility**: Provide real-time performance insights\n\n### 3. Operational Metrics\n- **Performance improvement**: 20% reduction in average execution time\n- **Error rate reduction**: 50% reduction in service task failures\n- **Resource optimization**: 30% reduction in resource usage\n- **Mean time to resolution**: 60% reduction in MTTR for issues\n\n## Implementation Roadmap\n\n### Phase 1: Core Foundation (Weeks 1-4)\n- Implement base ServiceTask class\n- Add basic OpenTelemetry instrumentation\n- Create file tracking system\n- Implement circuit breaker pattern\n\n### Phase 2: Advanced Features (Weeks 5-8)\n- Add performance tracking system\n- Implement intelligent error handling\n- Create declarative configuration system\n- Add async support\n\n### Phase 3: Analytics and Optimization (Weeks 9-12)\n- Implement predictive analytics\n- Add anomaly detection\n- Create performance optimization recommendations\n- Add advanced monitoring dashboards\n\n### Phase 4: Integration and Testing (Weeks 13-16)\n- Integrate with existing BPMN workflows\n- Comprehensive testing and validation\n- Performance benchmarking\n- Documentation and training\n\n## Risk Assessment\n\n### Technical Risks\n- **Performance overhead**: Risk of instrumentation adding significant overhead\n- **Complexity**: Risk of making the system too complex for simple use cases\n- **Compatibility**: Risk of breaking existing service task implementations\n\n### Mitigation Strategies\n- **Performance testing**: Comprehensive performance testing and optimization\n- **Gradual migration**: Provide migration path for existing implementations\n- **Backward compatibility**: Maintain compatibility with existing patterns\n- **Documentation**: Comprehensive documentation and examples\n\n## Conclusion\n\nThe Ultra-Advanced Base ServiceTask will revolutionize service task development in the WeaverGen BPMN workflow system by providing automatic instrumentation, intelligent error handling, and elegant developer experience. This foundation will enable developers to focus on business logic while the framework handles all aspects of observability, performance monitoring, and operational excellence.\n\nThe implementation will follow the BPMN-first philosophy while providing the most advanced and elegant service task framework available, setting new standards for workflow development and observability in the industry.\n\n---\n\n**Document Version**: 1.0  \n**Last Updated**: December 2024  \n**Maintainer**: WeaverGen Development Team "
        }
    ]
}