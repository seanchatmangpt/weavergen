{
    "sourceFile": "prd/weaver/BPMN-FIRST-GUIDE.md",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1751483455958,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1751483455958,
            "name": "Commit-0",
            "content": "# BPMN-First Development Guide for AI Code Assistance\n\n## Overview\n\nThis document provides comprehensive guidance for AI code assistance when working with BPMN-first development patterns in the WeaverGen v2 project. The project follows a strict \"BPMN First or Nothing\" philosophy where all business logic and workflows are defined in BPMN files and executed through a workflow engine.\n\n## Core Philosophy: BPMN First or Nothing\n\n### Key Principles\n\n1. **BPMN as Source of Truth**: All business logic, workflows, and process definitions must be in BPMN files\n2. **No Fallback Logic**: If BPMN workflow fails, the entire operation fails - no fallback to direct code execution\n3. **Workflow Engine Execution**: All operations go through the SpiffWorkflow BPMN engine\n4. **Service Task Integration**: Business logic is implemented as service tasks registered with the workflow engine\n5. **Observability Integration**: All operations are instrumented with OpenTelemetry spans\n\n### Error Handling Pattern\n\n```python\ntry:\n    # Execute BPMN workflow\n    instance = engine.start_workflow('ProcessName')\n    instance.workflow.data.update(workflow_data)\n    instance.run_until_user_input_required()\n    \n    if instance.workflow.is_completed():\n        # Success path\n        result_data = instance.workflow.data.get('result_key', {})\n        console.print(\"[green]✓[/green] Workflow completed successfully\")\n    else:\n        # Workflow incomplete - this is an error\n        console.print(\"[yellow]Workflow requires user input[/yellow]\")\n        span.set_status(Status(StatusCode.ERROR, \"Workflow incomplete\"))\n        raise typer.Exit(1)\n        \nexcept Exception as e:\n    span.record_exception(e)\n    span.set_status(Status(StatusCode.ERROR, str(e)))\n    console.print(f\"[red]FATAL: Workflow failed: {e}[/red]\")\n    console.print(\"[red]NO FALLBACK - BPMN FIRST OR NOTHING[/red]\")\n    raise typer.Exit(1)\n```\n\n## BPMN File Structure and Organization\n\n### Directory Structure\n\n```\nsrc/workflows/bpmn/\n├── agents/           # AI agent workflows\n│   ├── agent_analysis.bpmn\n│   ├── agent_communication.bpmn\n│   └── agent_generation.bpmn\n├── forge/            # Code generation workflows\n│   └── forge_init.bpmn\n└── xes/              # Process mining workflows\n    └── xes_analysis.bpmn\n```\n\n### BPMN File Naming Conventions\n\n- **Process ID**: `{Domain}Process` (e.g., `ForgeInitProcess`, `AgentAnalysisProcess`)\n- **File Name**: `{domain}_{operation}.bpmn` (e.g., `forge_init.bpmn`, `agent_analysis.bpmn`)\n- **Namespace**: `http://weavergen.com/{domain}`\n\n### BPMN Element Naming\n\n- **Tasks**: `Task_{Operation}` (e.g., `Task_ValidateInput`, `Task_CreateDirectories`)\n- **Gateways**: `Gateway_{Purpose}` (e.g., `Gateway_CheckExamples`, `Gateway_Validation`)\n- **Flows**: `Flow_{From}_{To}` (e.g., `Flow_ToValidateInput`, `Flow_YesExamples`)\n\n## Service Task Implementation Patterns\n\n### 1. Service Task Registration\n\n```python\ndef register_domain_tasks(environment):\n    \"\"\"Register all domain service tasks with the BPMN environment.\"\"\"\n    tasks = DomainServiceTasks()\n    \n    # Access environment globals\n    if hasattr(environment, 'globals'):\n        globals_dict = environment.globals\n    elif hasattr(environment, '_globals'):\n        globals_dict = environment._globals\n    else:\n        globals_dict = environment._TaskDataEnvironment__globals\n    \n    # Register task functions\n    globals_dict['domain_validate_params'] = tasks.validate_params\n    globals_dict['domain_create_files'] = tasks.create_files\n    globals_dict['domain_process_data'] = tasks.process_data\n```\n\n### 2. Service Task Implementation\n\n```python\nclass DomainServiceTasks:\n    \"\"\"Service task implementations for domain workflows.\"\"\"\n    \n    @staticmethod\n    @create_workflow_task\n    def validate_params(data: Dict[str, Any]) -> None:\n        \"\"\"Validate workflow parameters.\"\"\"\n        with tracer.start_as_current_span(\"domain.service.validate_params\") as span:\n            # Validate required parameters\n            if not data.get('required_param'):\n                raise ValueError(\"Required parameter is missing\")\n            \n            # Set defaults\n            data.setdefault('optional_param', 'default_value')\n            \n            # Add span attributes\n            span.set_attribute(\"param.required\", data.get('required_param'))\n            span.set_attribute(\"param.optional\", data.get('optional_param'))\n    \n    @staticmethod\n    @create_workflow_task\n    def create_files(data: Dict[str, Any]) -> None:\n        \"\"\"Create files and directories.\"\"\"\n        with tracer.start_as_current_span(\"domain.service.create_files\") as span:\n            output_dir = Path(data['output_dir'])\n            output_dir.mkdir(parents=True, exist_ok=True)\n            \n            # Create file content\n            content = f\"Generated content for {data['name']}\"\n            file_path = output_dir / f\"{data['name']}.txt\"\n            file_path.write_text(content)\n            \n            # Store results in workflow data\n            data['created_files'] = [str(file_path)]\n            span.set_attribute(\"files.created\", len(data['created_files']))\n```\n\n### 3. Workflow Task Decorator\n\n```python\ndef create_workflow_task(func: Callable) -> Callable:\n    \"\"\"Decorator to create a workflow task that accesses SpiffWorkflow data.\"\"\"\n    def wrapper():\n        # Access the execution context to get workflow data\n        import inspect\n        frame = inspect.currentframe()\n        \n        # Walk up the stack to find the SpiffWorkflow execution context\n        while frame:\n            locals_dict = frame.f_locals\n            \n            # Look for SpiffWorkflow task data\n            if 'task' in locals_dict:\n                task = locals_dict['task']\n                if hasattr(task, 'workflow') and hasattr(task.workflow, 'data'):\n                    workflow_data = task.workflow.data\n                    if isinstance(workflow_data, dict):\n                        return func(workflow_data)\n            \n            # Alternative: look for 'data' directly in context\n            if 'data' in locals_dict and isinstance(locals_dict['data'], dict):\n                return func(locals_dict['data'])\n            \n            frame = frame.f_back\n        \n        # Fallback if no data found\n        console.print(\"[red]Warning: No workflow data found in execution context[/red]\")\n        return func({})\n    \n    # Preserve function metadata\n    wrapper.__name__ = func.__name__\n    wrapper.__doc__ = func.__doc__\n    return wrapper\n```\n\n## BPMN Engine Integration\n\n### 1. Engine Initialization\n\n```python\ndef get_bpmn_engine():\n    \"\"\"Get or create BPMN engine with domain tasks registered.\"\"\"\n    global _engine, _environment\n    if _engine is None:\n        _environment = WeaverGenServiceEnvironment()\n        register_domain_tasks(_environment)\n        _engine = SimpleBpmnEngine(_environment)\n        \n        # Load domain workflows\n        workflow_dir = Path(__file__).parent.parent.parent / \"workflows\" / \"bpmn\" / \"domain\"\n        if workflow_dir.exists():\n            for bpmn_file in workflow_dir.glob(\"*.bpmn\"):\n                try:\n                    _engine.parser.add_bpmn_file(str(bpmn_file))\n                    for process_id in _engine.parser.get_process_ids():\n                        spec = _engine.parser.get_spec(process_id)\n                        _engine.specs[process_id] = spec\n                        console.print(f\"[green]✓[/green] Loaded domain workflow: {process_id}\")\n                except Exception as e:\n                    console.print(f\"[red]ERROR: Could not load {bpmn_file}: {e}[/red]\")\n    \n    return _engine, _environment\n```\n\n### 2. Workflow Execution\n\n```python\ndef execute_workflow(process_name: str, workflow_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute a BPMN workflow with given data.\"\"\"\n    engine, environment = get_bpmn_engine()\n    \n    # Start workflow\n    instance = engine.start_workflow(process_name)\n    instance.workflow.data.update(workflow_data)\n    \n    # Run to completion\n    instance.run_until_user_input_required()\n    \n    if instance.workflow.is_completed():\n        return instance.workflow.data\n    else:\n        raise RuntimeError(f\"Workflow {process_name} did not complete\")\n```\n\n## BPMN File Patterns\n\n### 1. Basic Workflow Structure\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<bpmn:definitions xmlns:bpmn=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" \n                  xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" \n                  xmlns:dc=\"http://www.omg.org/spec/DD/20100524/DC\" \n                  xmlns:di=\"http://www.omg.org/spec/DD/20100524/DI\" \n                  id=\"Definitions_Domain\" \n                  targetNamespace=\"http://weavergen.com/domain\">\n  \n  <bpmn:process id=\"DomainProcess\" name=\"Domain Operation\" isExecutable=\"true\">\n    \n    <bpmn:startEvent id=\"StartEvent\" name=\"Start Operation\">\n      <bpmn:outgoing>Flow_ToValidate</bpmn:outgoing>\n    </bpmn:startEvent>\n    \n    <bpmn:scriptTask id=\"Task_Validate\" name=\"Validate Input\">\n      <bpmn:incoming>Flow_ToValidate</bpmn:incoming>\n      <bpmn:outgoing>Flow_ToProcess</bpmn:outgoing>\n      <bpmn:script>domain_validate_params()</bpmn:script>\n    </bpmn:scriptTask>\n    \n    <bpmn:scriptTask id=\"Task_Process\" name=\"Process Data\">\n      <bpmn:incoming>Flow_ToProcess</bpmn:incoming>\n      <bpmn:outgoing>Flow_ToEnd</bpmn:outgoing>\n      <bpmn:script>domain_process_data()</bpmn:script>\n    </bpmn:scriptTask>\n    \n    <bpmn:endEvent id=\"EndEvent\" name=\"Operation Complete\">\n      <bpmn:incoming>Flow_ToEnd</bpmn:incoming>\n    </bpmn:endEvent>\n    \n    <!-- Sequence Flows -->\n    <bpmn:sequenceFlow id=\"Flow_ToValidate\" sourceRef=\"StartEvent\" targetRef=\"Task_Validate\"/>\n    <bpmn:sequenceFlow id=\"Flow_ToProcess\" sourceRef=\"Task_Validate\" targetRef=\"Task_Process\"/>\n    <bpmn:sequenceFlow id=\"Flow_ToEnd\" sourceRef=\"Task_Process\" targetRef=\"EndEvent\"/>\n    \n  </bpmn:process>\n</bpmn:definitions>\n```\n\n### 2. Conditional Workflow with Gateway\n\n```xml\n<bpmn:exclusiveGateway id=\"Gateway_CheckCondition\" name=\"Check Condition?\">\n  <bpmn:incoming>Flow_ToGateway</bpmn:incoming>\n  <bpmn:outgoing>Flow_YesCondition</bpmn:outgoing>\n  <bpmn:outgoing>Flow_NoCondition</bpmn:outgoing>\n</bpmn:exclusiveGateway>\n\n<bpmn:scriptTask id=\"Task_ProcessYes\" name=\"Process Yes Path\">\n  <bpmn:incoming>Flow_YesCondition</bpmn:incoming>\n  <bpmn:outgoing>Flow_ToJoin</bpmn:outgoing>\n  <bpmn:script>domain_process_yes_path()</bpmn:script>\n</bpmn:scriptTask>\n\n<bpmn:scriptTask id=\"Task_ProcessNo\" name=\"Process No Path\">\n  <bpmn:incoming>Flow_NoCondition</bpmn:incoming>\n  <bpmn:outgoing>Flow_ToJoin</bpmn:outgoing>\n  <bpmn:script>domain_process_no_path()</bpmn:script>\n</bpmn:scriptTask>\n\n<bpmn:parallelGateway id=\"Gateway_Join\" name=\"Join Paths\">\n  <bpmn:incoming>Flow_ToJoin</bpmn:incoming>\n  <bpmn:incoming>Flow_ToJoin</bpmn:incoming>\n  <bpmn:outgoing>Flow_ToEnd</bpmn:outgoing>\n</bpmn:parallelGateway>\n```\n\n### 3. Parallel Processing\n\n```xml\n<bpmn:parallelGateway id=\"Gateway_ParallelStart\" name=\"Start Parallel\">\n  <bpmn:incoming>Flow_ToParallel</bpmn:incoming>\n  <bpmn:outgoing>Flow_ToTask1</bpmn:outgoing>\n  <bpmn:outgoing>Flow_ToTask2</bpmn:outgoing>\n</bpmn:parallelGateway>\n\n<bpmn:scriptTask id=\"Task_Parallel1\" name=\"Parallel Task 1\">\n  <bpmn:incoming>Flow_ToTask1</bpmn:incoming>\n  <bpmn:outgoing>Flow_FromTask1</bpmn:outgoing>\n  <bpmn:script>domain_parallel_task_1()</bpmn:script>\n</bpmn:scriptTask>\n\n<bpmn:scriptTask id=\"Task_Parallel2\" name=\"Parallel Task 2\">\n  <bpmn:incoming>Flow_ToTask2</bpmn:incoming>\n  <bpmn:outgoing>Flow_FromTask2</bpmn:outgoing>\n  <bpmn:script>domain_parallel_task_2()</bpmn:script>\n</bpmn:scriptTask>\n\n<bpmn:parallelGateway id=\"Gateway_ParallelJoin\" name=\"Join Parallel\">\n  <bpmn:incoming>Flow_FromTask1</bpmn:incoming>\n  <bpmn:incoming>Flow_FromTask2</bpmn:incoming>\n  <bpmn:outgoing>Flow_ToEnd</bpmn:outgoing>\n</bpmn:parallelGateway>\n```\n\n## CLI Command Integration\n\n### 1. Command Structure\n\n```python\n@domain_app.command()\ndef operation(\n    input_file: Path = typer.Argument(..., help=\"Input file\"),\n    output: Optional[Path] = typer.Option(None, \"--output\", \"-o\", help=\"Output file\"),\n    verbose: bool = typer.Option(False, \"--verbose\", \"-v\", help=\"Verbose output\")\n):\n    \"\"\"Execute domain operation through BPMN workflow.\"\"\"\n    \n    with cli_command_span(\"domain.operation\") as span:\n        span.set_attribute(\"input_file\", str(input_file))\n        span.set_attribute(\"output_file\", str(output) if output else \"none\")\n        span.set_attribute(\"verbose\", verbose)\n        \n        try:\n            # Get BPMN engine\n            engine, environment = get_bpmn_engine()\n            \n            # Prepare workflow data\n            workflow_data = {\n                'input_file': str(input_file),\n                'output_file': str(output) if output else None,\n                'verbose': verbose\n            }\n            \n            # Execute BPMN workflow\n            console.print(f\"[cyan]Executing domain workflow: DomainProcess[/cyan]\")\n            \n            instance = engine.start_workflow('DomainProcess')\n            instance.workflow.data.update(workflow_data)\n            \n            # Run workflow to completion\n            instance.run_until_user_input_required()\n            \n            if instance.workflow.is_completed():\n                # Get results from workflow\n                result_data = instance.workflow.data.get('operation_result', {})\n                console.print(\"[green]✓[/green] Domain operation completed successfully\")\n                \n                # Display results\n                _display_operation_results(result_data)\n                \n                span.set_status(Status(StatusCode.OK))\n            else:\n                console.print(\"[yellow]Workflow requires user input[/yellow]\")\n                span.set_status(Status(StatusCode.ERROR, \"Workflow incomplete\"))\n                raise typer.Exit(1)\n                \n        except Exception as e:\n            span.record_exception(e)\n            span.set_status(Status(StatusCode.ERROR, str(e)))\n            console.print(f\"[red]FATAL: Domain operation workflow failed: {e}[/red]\")\n            console.print(\"[red]NO FALLBACK - BPMN FIRST OR NOTHING[/red]\")\n            raise typer.Exit(1)\n```\n\n### 2. Error Handling Pattern\n\n```python\ndef _display_operation_results(result_data: Dict[str, Any]) -> None:\n    \"\"\"Display operation results.\"\"\"\n    if result_data.get('success'):\n        console.print(f\"[green]✓[/green] Operation successful\")\n        if result_data.get('output_files'):\n            console.print(f\"Generated files: {result_data['output_files']}\")\n    else:\n        console.print(f\"[red]✗[/red] Operation failed: {result_data.get('error', 'Unknown error')}\")\n```\n\n## Observability Integration\n\n### 1. Span Creation\n\n```python\n@semantic_span(\"domain.operation\", \"execute_workflow\")\ndef execute_domain_workflow(workflow_data: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"Execute domain workflow with span tracking.\"\"\"\n    # Implementation here\n    pass\n```\n\n### 2. Span Attributes\n\n```python\ndef domain_operation(data: Dict[str, Any]) -> None:\n    \"\"\"Domain operation with span tracking.\"\"\"\n    with tracer.start_as_current_span(\"domain.service.operation\") as span:\n        # Set span attributes\n        span.set_attribute(\"operation.type\", data.get('operation_type', 'unknown'))\n        span.set_attribute(\"input.size\", len(str(data.get('input', ''))))\n        span.set_attribute(\"output.expected\", data.get('output_expected', False))\n        \n        # Perform operation\n        result = perform_operation(data)\n        \n        # Add result attributes\n        span.set_attribute(\"operation.success\", result.get('success', False))\n        span.set_attribute(\"output.size\", len(str(result.get('output', ''))))\n```\n\n### 3. Event Recording\n\n```python\ndef domain_process_data(data: Dict[str, Any]) -> None:\n    \"\"\"Process data with event recording.\"\"\"\n    with tracer.start_as_current_span(\"domain.service.process_data\") as span:\n        # Record start event\n        span.add_event(\"data_processing.started\", {\n            \"data_size\": len(str(data.get('input', ''))),\n            \"processing_type\": data.get('processing_type', 'default')\n        })\n        \n        # Process data\n        result = process_data(data)\n        \n        # Record completion event\n        span.add_event(\"data_processing.completed\", {\n            \"result_size\": len(str(result)),\n            \"processing_time_ms\": result.get('processing_time', 0)\n        })\n```\n\n## Testing Patterns\n\n### 1. BPMN Workflow Testing\n\n```python\ndef test_domain_workflow():\n    \"\"\"Test domain BPMN workflow execution.\"\"\"\n    # Initialize engine\n    environment = WeaverGenServiceEnvironment()\n    register_domain_tasks(environment)\n    engine = SimpleBpmnEngine(environment)\n    \n    # Load workflow\n    workflow_dir = Path(\"src/workflows/bpmn/domain\")\n    for bpmn_file in workflow_dir.glob(\"*.bpmn\"):\n        engine.parser.add_bpmn_file(str(bpmn_file))\n    \n    # Test workflow execution\n    instance = engine.start_workflow('DomainProcess')\n    instance.workflow.data.update({\n        'input_file': 'test_input.txt',\n        'output_file': 'test_output.txt'\n    })\n    \n    # Run workflow\n    instance.run_until_user_input_required()\n    \n    # Assert completion\n    assert instance.workflow.is_completed()\n    assert 'operation_result' in instance.workflow.data\n```\n\n### 2. Service Task Testing\n\n```python\ndef test_domain_service_tasks():\n    \"\"\"Test domain service tasks.\"\"\"\n    tasks = DomainServiceTasks()\n    \n    # Test with mock data\n    test_data = {\n        'input_file': 'test.txt',\n        'output_file': 'output.txt'\n    }\n    \n    # Test validation\n    tasks.validate_params(test_data)\n    assert 'validated' in test_data\n    \n    # Test processing\n    tasks.process_data(test_data)\n    assert 'processed' in test_data\n```\n\n## Best Practices for AI Code Assistance\n\n### 1. Always Start with BPMN\n\nWhen implementing new functionality:\n\n1. **Design the BPMN workflow first** - Define the process flow, tasks, and decision points\n2. **Create the BPMN file** - Implement the workflow in XML format\n3. **Implement service tasks** - Create the Python functions that will be called by the workflow\n4. **Register tasks with engine** - Connect the service tasks to the BPMN engine\n5. **Create CLI command** - Implement the CLI interface that executes the workflow\n\n### 2. Error Handling\n\n- **No fallbacks**: If BPMN workflow fails, the entire operation fails\n- **Clear error messages**: Provide specific error information for debugging\n- **Span recording**: Record all errors in OpenTelemetry spans\n- **Graceful degradation**: Handle workflow incompletion scenarios\n\n### 3. Data Flow\n\n- **Workflow data**: All data flows through the workflow's data dictionary\n- **Service task access**: Use the `@create_workflow_task` decorator to access workflow data\n- **Result storage**: Store results in the workflow data for access by subsequent tasks\n- **Data validation**: Validate data at the beginning of workflows\n\n### 4. Observability\n\n- **Span creation**: Create spans for all major operations\n- **Attribute setting**: Set relevant attributes on spans for monitoring\n- **Event recording**: Record important events during workflow execution\n- **Error tracking**: Record exceptions and error conditions\n\n### 5. Testing\n\n- **Workflow testing**: Test complete workflow execution\n- **Service task testing**: Test individual service tasks\n- **Error scenario testing**: Test workflow behavior under error conditions\n- **Integration testing**: Test workflow integration with external systems\n\n## Common Patterns and Anti-Patterns\n\n### ✅ Good Patterns\n\n1. **BPMN-first design**: Always start with BPMN workflow design\n2. **Service task separation**: Keep business logic in service tasks\n3. **Data flow through workflow**: Pass data through workflow data dictionary\n4. **Comprehensive error handling**: Handle all error scenarios in BPMN\n5. **Observability integration**: Instrument all operations with spans\n\n### ❌ Anti-Patterns\n\n1. **Direct code execution**: Implementing logic outside of BPMN workflows\n2. **Fallback mechanisms**: Providing fallback logic when BPMN fails\n3. **Bypassing workflow engine**: Direct function calls instead of workflow execution\n4. **Missing error handling**: Not handling workflow failure scenarios\n5. **Poor observability**: Not instrumenting operations with spans\n\n## Conclusion\n\nThe BPMN-first approach in WeaverGen v2 ensures that all business logic is defined in a standardized, visual format that can be easily understood, modified, and monitored. This approach provides several benefits:\n\n1. **Visual Process Definition**: BPMN provides a clear visual representation of business processes\n2. **Standardized Execution**: All operations follow the same execution pattern through the workflow engine\n3. **Comprehensive Observability**: All operations are instrumented with OpenTelemetry\n4. **Error Resilience**: Consistent error handling across all operations\n5. **Maintainability**: Clear separation between process definition and implementation\n\nWhen providing AI code assistance for this project, always prioritize BPMN-first development and ensure that all business logic flows through the workflow engine rather than being implemented as direct code execution. "
        }
    ]
}