#!/usr/bin/env python3
"""
REAL Working Enterprise System using Pydantic AI with Ollama
Uses actual generated Pydantic models and OllamaModel for real LLM calls
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Pydantic and Pydantic AI
from pydantic import BaseModel, Field
from pydantic_ai import Agent
from pydantic_ai.models.ollama import OllamaModel

# OTel for real span communication
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.resources import Resource
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor
from opentelemetry.trace import Status, StatusCode

# ============= Generated Pydantic Models (from Weaver Forge) =============
# These would be GENERATED by Weaver Forge from semantic conventions

class StrategicDecision(BaseModel):
    """Strategic decision output from executive agent"""
    decision: str = Field(..., description="The decision made (approve/reject/defer/investigate)")
    reasoning: str = Field(..., description="Detailed reasoning behind the decision")
    confidence: float = Field(..., ge=0.0, le=1.0, description="Confidence level 0-1")
    alternatives_considered: List[str] = Field(default_factory=list, description="Other options considered")
    estimated_impact: str = Field(..., description="Expected business impact")
    risk_assessment: str = Field(..., description="Risk level and mitigation")
    next_steps: List[str] = Field(default_factory=list, description="Recommended next steps")
    investment_required: Optional[float] = Field(None, description="Investment amount if applicable")

class BacklogPrioritization(BaseModel):
    """Backlog prioritization decision from CPO"""
    prioritized_ids: List[str] = Field(..., description="Feature IDs in priority order")
    wsjf_scores: Dict[str, float] = Field(..., description="WSJF score for each feature")
    reasoning_per_item: Dict[str, str] = Field(..., description="Why each item is prioritized")
    capacity_allocation: Dict[str, int] = Field(..., description="Story points per feature")
    dependencies_identified: List[Dict[str, str]] = Field(default_factory=list)
    sprint_assignments: Dict[str, int] = Field(..., description="Which sprint for each feature")
    confidence: float = Field(..., ge=0.0, le=1.0)

class ImpedimentResolution(BaseModel):
    """Impediment resolution plan from Scrum Master"""
    impediment_id: str = Field(..., description="ID of the impediment")
    severity_assessment: str = Field(..., pattern="^(low|medium|high|critical)$")
    root_causes: List[str] = Field(..., min_items=1, description="Identified root causes")
    resolution_plan: str = Field(..., description="Detailed resolution approach")
    resources_needed: List[str] = Field(..., description="Resources required")
    estimated_resolution_time: str = Field(..., description="Time to resolve")
    escalation_required: bool = Field(..., description="Needs executive attention")
    similar_past_issues: List[str] = Field(default_factory=list)
    preventive_measures: List[str] = Field(..., description="How to prevent recurrence")

class TeamStatusReport(BaseModel):
    """Team status report for Scrum of Scrums"""
    team_id: str = Field(..., description="Team identifier")
    sprint_progress: int = Field(..., ge=0, le=100, description="Sprint progress percentage")
    stories_completed: int = Field(..., ge=0)
    stories_remaining: int = Field(..., ge=0)
    velocity_trend: str = Field(..., pattern="^(improving|stable|declining)$")
    impediments: List[str] = Field(default_factory=list, description="Current impediments")
    dependencies: List[str] = Field(default_factory=list, description="Dependencies on other teams")
    confidence_vote: float = Field(..., ge=1.0, le=5.0, description="Team confidence (1-5)")

# ============= Real OTel Setup =============

def setup_real_telemetry():
    """Configure real OpenTelemetry with proper span export"""
    resource = Resource.create({
        "service.name": "enterprise-sas-pydantic-ai",
        "service.version": "3.0.0",
        "deployment.environment": "production",
        "sas.implementation": "pydantic_ai_real"
    })
    
    provider = TracerProvider(resource=resource)
    
    # Console exporter for visibility
    console_exporter = ConsoleSpanExporter()
    provider.add_span_processor(BatchSpanProcessor(console_exporter))
    
    trace.set_tracer_provider(provider)
    return trace.get_tracer(__name__)

tracer = setup_real_telemetry()

# ============= Base Agent with Pydantic AI =============

class EnterpriseAgent:
    """Base class for all enterprise agents using Pydantic AI"""
    
    def __init__(self, agent_id: str, name: str, role: str):
        self.agent_id = agent_id
        self.name = name
        self.role = role
        
        # Use OllamaModel (not OpenAIModel)
        self.model = OllamaModel(model_name='qwen3:latest')
        
        # Conversation history
        self.decisions_made = []
        self.messages_sent = []
        
    def get_system_prompt(self) -> str:
        """Override in subclasses"""
        return f"You are a {self.role} in an enterprise Scrum at Scale implementation."

# ============= CEO Agent =============

class CEOAgent(EnterpriseAgent):
    """CEO making strategic decisions"""
    
    def __init__(self):
        super().__init__("ceo-001", "Sarah Chen", "CEO")
        self.portfolio_value = 5000000000  # $5B
        
    def get_system_prompt(self) -> str:
        return """You are Sarah Chen, CEO of a large enterprise with 5000+ employees and a $5B portfolio.
        
Your responsibilities:
- Strategic vision and direction
- Major investment decisions ($10M+)
- Digital transformation leadership
- Stakeholder value creation
- Risk management

Current focus areas:
1. AI and automation transformation
2. Market expansion
3. Operational efficiency

Make decisions that balance growth, innovation, and risk. Consider long-term impact."""

    async def make_strategic_decision(self, context: Dict[str, Any]) -> StrategicDecision:
        """Make a strategic decision using Pydantic AI"""
        
        with tracer.start_as_current_span("ceo.strategic_decision") as span:
            span.set_attribute("agent.id", self.agent_id)
            span.set_attribute("agent.name", self.name)
            span.set_attribute("decision.type", "strategic")
            
            # Create agent with output schema
            decision_agent = Agent(
                model=self.model,
                output_type=StrategicDecision,
                system_prompt=self.get_system_prompt()
            )
            
            # Build context prompt
            prompt = f"""Analyze this strategic opportunity and make a decision:

Context:
{json.dumps(context, indent=2)}

Consider:
1. ROI and financial impact
2. Strategic alignment with digital transformation
3. Risk vs reward
4. Resource requirements
5. Market timing

Provide a comprehensive strategic decision."""

            print(f"\nðŸ¤” {self.name} analyzing strategic opportunity...")
            start_time = time.time()
            
            # Real LLM call via Pydantic AI
            result = await decision_agent.run(prompt)
            
            thinking_time = time.time() - start_time
            span.set_attribute("thinking_time_seconds", thinking_time)
            
            decision = result.output
            
            # Record in span
            span.set_attribute("decision.made", decision.decision)
            span.set_attribute("decision.confidence", decision.confidence)
            span.set_attribute("decision.investment", decision.investment_required or 0)
            span.set_attribute("message.content", decision.model_dump_json())
            
            # Store decision
            self.decisions_made.append({
                "timestamp": datetime.utcnow(),
                "decision": decision.model_dump(),
                "context": context
            })
            
            print(f"âœ… CEO Decision: {decision.decision}")
            print(f"   Confidence: {decision.confidence:.1%}")
            print(f"   Reasoning: {decision.reasoning[:200]}...")
            print(f"   Investment: ${decision.investment_required:,.0f}" if decision.investment_required else "   Investment: N/A")
            
            return decision

# ============= CPO Agent =============

class CPOAgent(EnterpriseAgent):
    """Chief Product Owner managing portfolio"""
    
    def __init__(self):
        super().__init__("cpo-001", "David Kumar", "Chief Product Owner")
        self.portfolio_value = 1200000000  # $1.2B
        self.release_trains = ["platform", "mobile", "data", "infrastructure", "ai_ml"]
        
    def get_system_prompt(self) -> str:
        return """You are David Kumar, Chief Product Owner managing a $1.2B product portfolio.

You oversee:
- 5 release trains (Platform, Mobile, Data, Infrastructure, AI/ML)
- 45 Product Owners
- 500+ backlog items

Your approach:
- Use WSJF (Weighted Shortest Job First) for prioritization
- Balance customer value with technical debt
- Consider cross-train dependencies
- Optimize for flow efficiency

Always calculate: WSJF = (Business Value + Time Criticality + Risk Reduction) / Job Size"""

    async def prioritize_backlog(self, items: List[Dict[str, Any]]) -> BacklogPrioritization:
        """Prioritize backlog items using WSJF"""
        
        with tracer.start_as_current_span("cpo.backlog_prioritization") as span:
            span.set_attribute("agent.id", self.agent_id)
            span.set_attribute("agent.name", self.name)
            span.set_attribute("backlog.items_count", len(items))
            
            # Create prioritization agent
            prioritization_agent = Agent(
                model=self.model,
                output_type=BacklogPrioritization,
                system_prompt=self.get_system_prompt()
            )
            
            # Build prioritization prompt
            prompt = f"""Prioritize these backlog items using WSJF methodology:

Items to prioritize:
{json.dumps(items, indent=2)}

Available capacity: 55 story points
Current sprint: 143

Requirements:
1. Calculate WSJF score for each item
2. Identify dependencies between items
3. Allocate capacity optimally
4. Assign items to sprints
5. Provide clear reasoning for each prioritization decision"""

            print(f"\nðŸ“Š {self.name} prioritizing backlog...")
            start_time = time.time()
            
            # Real LLM call
            result = await prioritization_agent.run(prompt)
            
            thinking_time = time.time() - start_time
            span.set_attribute("thinking_time_seconds", thinking_time)
            
            prioritization = result.output
            
            # Record in span
            span.set_attribute("prioritization.confidence", prioritization.confidence)
            span.set_attribute("prioritization.top_item", prioritization.prioritized_ids[0] if prioritization.prioritized_ids else "none")
            span.set_attribute("message.content", prioritization.model_dump_json())
            
            print(f"âœ… Backlog Prioritized:")
            print(f"   Top priority: {prioritization.prioritized_ids[0] if prioritization.prioritized_ids else 'None'}")
            print(f"   Confidence: {prioritization.confidence:.1%}")
            print(f"   Dependencies found: {len(prioritization.dependencies_identified)}")
            
            return prioritization

# ============= Scrum Master Agent =============

class ScrumMasterAgent(EnterpriseAgent):
    """Scrum Master facilitating teams and removing impediments"""
    
    def __init__(self, teams: List[str]):
        super().__init__(f"sm-{teams[0]}", f"SM for {teams[0]}", "Scrum Master")
        self.teams = teams
        self.impediments_resolved = 0
        
    def get_system_prompt(self) -> str:
        return f"""You are an experienced Scrum Master facilitating {len(self.teams)} teams: {', '.join(self.teams)}.

Your expertise:
- 10+ years of Agile experience
- Certified SAFe SPC (Scaled Agile Program Consultant)
- Expert in impediment resolution
- Strong technical background

Your approach:
- Servant leadership
- Root cause analysis using 5 Whys
- Systemic impediment removal
- Team empowerment
- Continuous improvement

Focus on quick resolution and preventing recurrence."""

    async def resolve_impediment(self, impediment: Dict[str, Any]) -> ImpedimentResolution:
        """Analyze and resolve impediment"""
        
        with tracer.start_as_current_span("sm.impediment_resolution") as span:
            span.set_attribute("agent.id", self.agent_id)
            span.set_attribute("agent.name", self.name)
            span.set_attribute("impediment.id", impediment.get("id", "unknown"))
            span.set_attribute("impediment.severity", impediment.get("severity", "unknown"))
            
            # Create resolution agent
            resolution_agent = Agent(
                model=self.model,
                output_type=ImpedimentResolution,
                system_prompt=self.get_system_prompt()
            )
            
            # Build resolution prompt
            prompt = f"""Analyze and resolve this impediment:

Impediment Details:
{json.dumps(impediment, indent=2)}

Previous similar issues:
- "Pipeline memory leak Q2 2023" - Resolved by upgrading Jenkins
- "Build failures Q4 2023" - Fixed by plugin compatibility matrix

Perform:
1. Root cause analysis (5 Whys)
2. Immediate resolution plan
3. Resource requirements
4. Preventive measures
5. Escalation assessment"""

            print(f"\nðŸ”§ {self.name} analyzing impediment...")
            start_time = time.time()
            
            # Real LLM call
            result = await resolution_agent.run(prompt)
            
            thinking_time = time.time() - start_time
            span.set_attribute("thinking_time_seconds", thinking_time)
            
            resolution = result.output
            
            # Record in span
            span.set_attribute("resolution.escalation_required", resolution.escalation_required)
            span.set_attribute("resolution.severity", resolution.severity_assessment)
            span.set_attribute("message.content", resolution.model_dump_json())
            
            print(f"âœ… Resolution Plan:")
            print(f"   Severity: {resolution.severity_assessment}")
            print(f"   Root causes: {len(resolution.root_causes)}")
            print(f"   Resolution time: {resolution.estimated_resolution_time}")
            print(f"   Escalation needed: {'Yes' if resolution.escalation_required else 'No'}")
            
            self.impediments_resolved += 1
            
            return resolution

    async def report_team_status(self, sprint_data: Dict[str, Any]) -> TeamStatusReport:
        """Generate team status report"""
        
        with tracer.start_as_current_span("sm.team_status_report") as span:
            span.set_attribute("agent.id", self.agent_id)
            span.set_attribute("agent.name", self.name)
            
            # Create reporting agent
            report_agent = Agent(
                model=self.model,
                output_type=TeamStatusReport,
                system_prompt=self.get_system_prompt()
            )
            
            prompt = f"""Generate team status report:

Sprint Data:
{json.dumps(sprint_data, indent=2)}

Provide concise status including progress, velocity trend, impediments, and team confidence."""

            result = await report_agent.run(prompt)
            report = result.output
            
            span.set_attribute("team.progress", report.sprint_progress)
            span.set_attribute("team.confidence", report.confidence_vote)
            
            return report

# ============= Enterprise Meeting Runner =============

class EnterpriseScaledAgileMeeting:
    """Conducts real Scrum at Scale meetings with Pydantic AI agents"""
    
    def __init__(self, meeting_type: str):
        self.meeting_type = meeting_type
        self.meeting_id = f"{meeting_type}-{datetime.utcnow().timestamp()}"
        self.decisions = []
        self.action_items = []
        
    async def run_executive_action_team(self):
        """Run EAT meeting with real AI decisions"""
        
        with tracer.start_as_current_span("meeting.eat") as span:
            span.set_attribute("meeting.type", "executive_action_team")
            span.set_attribute("meeting.id", self.meeting_id)
            
            print("\n" + "="*60)
            print("ðŸ›ï¸ EXECUTIVE ACTION TEAM MEETING")
            print("="*60)
            
            # Create CEO
            ceo = CEOAgent()
            
            # Strategic investment decision
            investment_context = {
                "proposal": "Enterprise AI Development Platform",
                "investment_required": 75000000,  # $75M
                "expected_roi": 225000000,  # $225M over 3 years
                "timeline_years": 3,
                "strategic_alignment": "digital_transformation",
                "market_opportunity": "First-mover advantage in our industry",
                "risk_factors": [
                    "Technology maturity",
                    "Talent acquisition",
                    "Integration complexity"
                ],
                "benefits": [
                    "30% faster time-to-market",
                    "50% reduction in defects",
                    "Enable AI-assisted development",
                    "Competitive differentiation"
                ]
            }
            
            # CEO makes strategic decision
            decision = await ceo.make_strategic_decision(investment_context)
            
            self.decisions.append({
                "agent": ceo.name,
                "type": "strategic",
                "decision": decision.model_dump()
            })
            
            # Generate action items from decision
            for next_step in decision.next_steps[:3]:
                self.action_items.append({
                    "action": next_step,
                    "owner": "Executive Team",
                    "due_date": "End of Q1"
                })
            
            span.set_attribute("decisions.count", len(self.decisions))
            span.set_attribute("action_items.count", len(self.action_items))
    
    async def run_executive_metascrum(self):
        """Run EMS meeting for backlog prioritization"""
        
        with tracer.start_as_current_span("meeting.ems") as span:
            span.set_attribute("meeting.type", "executive_metascrum")
            span.set_attribute("meeting.id", self.meeting_id)
            
            print("\n" + "="*60)
            print("ðŸ’¼ EXECUTIVE METASCRUM")
            print("="*60)
            
            # Create CPO
            cpo = CPOAgent()
            
            # Backlog items to prioritize
            backlog_items = [
                {
                    "id": "FEAT-001",
                    "title": "Real-time Analytics Dashboard",
                    "business_value": 85,
                    "time_criticality": 90,
                    "risk_reduction": 60,
                    "effort": 21,
                    "dependencies": ["FEAT-003"],
                    "teams_needed": ["platform", "data"]
                },
                {
                    "id": "FEAT-002",
                    "title": "Mobile Offline Sync",
                    "business_value": 70,
                    "time_criticality": 50,
                    "risk_reduction": 40,
                    "effort": 34,
                    "dependencies": [],
                    "teams_needed": ["mobile"]
                },
                {
                    "id": "FEAT-003",
                    "title": "API Gateway Modernization",
                    "business_value": 60,
                    "time_criticality": 80,
                    "risk_reduction": 85,
                    "effort": 13,
                    "dependencies": [],
                    "teams_needed": ["platform", "infrastructure"]
                },
                {
                    "id": "FEAT-004",
                    "title": "ML-based Fraud Detection",
                    "business_value": 95,
                    "time_criticality": 70,
                    "risk_reduction": 90,
                    "effort": 55,
                    "dependencies": ["FEAT-003"],
                    "teams_needed": ["ai_ml", "data"]
                }
            ]
            
            # CPO prioritizes backlog
            prioritization = await cpo.prioritize_backlog(backlog_items)
            
            self.decisions.append({
                "agent": cpo.name,
                "type": "prioritization",
                "decision": prioritization.model_dump()
            })
            
            span.set_attribute("backlog.prioritized_count", len(prioritization.prioritized_ids))
    
    async def run_scrum_of_scrums(self):
        """Run SoS meeting for impediment resolution"""
        
        with tracer.start_as_current_span("meeting.sos") as span:
            span.set_attribute("meeting.type", "scrum_of_scrums")
            span.set_attribute("meeting.id", self.meeting_id)
            
            print("\n" + "="*60)
            print("ðŸ”„ SCRUM OF SCRUMS")
            print("="*60)
            
            # Create Scrum Masters
            sm_platform = ScrumMasterAgent(["Platform", "Infrastructure"])
            sm_mobile = ScrumMasterAgent(["Mobile", "Web"])
            
            # Team status reports
            print("\nðŸ“Š Team Status Reports:")
            
            platform_status = await sm_platform.report_team_status({
                "sprint_number": 143,
                "stories_planned": 8,
                "stories_completed": 5,
                "stories_in_progress": 3,
                "blockers": ["CI/CD pipeline intermittent failures"]
            })
            
            print(f"\n{sm_platform.teams[0]} Team:")
            print(f"   Progress: {platform_status.sprint_progress}%")
            print(f"   Velocity: {platform_status.velocity_trend}")
            print(f"   Confidence: {platform_status.confidence_vote}/5")
            
            # Critical impediment
            impediment = {
                "id": "IMP-2024-01-15",
                "description": "CI/CD pipeline failing intermittently, blocking deployments for 3 teams",
                "severity": "high",
                "teams_affected": ["Platform", "Infrastructure", "Mobile"],
                "duration_days": 2,
                "business_impact": "Cannot deploy hotfix for production issue",
                "attempted_solutions": [
                    "Restarted Jenkins agents",
                    "Increased memory allocation",
                    "Cleared build cache"
                ],
                "cost_of_delay": 25000  # per day
            }
            
            # Scrum Master resolves impediment
            resolution = await sm_platform.resolve_impediment(impediment)
            
            self.decisions.append({
                "agent": sm_platform.name,
                "type": "impediment_resolution",
                "decision": resolution.model_dump()
            })
            
            # Create action items from resolution
            self.action_items.extend([
                {
                    "action": resolution.resolution_plan,
                    "owner": sm_platform.name,
                    "due_date": "Within 24 hours"
                }
            ])
            
            for measure in resolution.preventive_measures[:2]:
                self.action_items.append({
                    "action": f"Implement: {measure}",
                    "owner": "DevOps Team",
                    "due_date": "Sprint 144"
                })
            
            span.set_attribute("impediments.resolved", 1)
            span.set_attribute("impediments.escalated", 1 if resolution.escalation_required else 0)

# ============= Main Runner =============

async def run_real_enterprise_sas():
    """Run the REAL enterprise Scrum at Scale with Pydantic AI and Ollama"""
    
    print("ðŸ¢ REAL Enterprise Scrum at Scale with Pydantic AI")
    print("ðŸ¤– Using OllamaModel with qwen3:latest")
    print("ðŸ“Š Generated Pydantic models for structured output")
    print("ðŸ“¡ OpenTelemetry spans for all communication")
    print("="*60)
    
    # Test Ollama connection
    print("\nðŸ”Œ Testing Ollama connection...")
    try:
        test_model = OllamaModel(model_name='qwen3:latest')
        test_agent = Agent(
            model=test_model,
            output_type=str,
            system_prompt="You are a test agent. Respond with 'Connected!'"
        )
        result = await test_agent.run("Say hello")
        print(f"âœ… Ollama connected: {result.output}")
    except Exception as e:
        print(f"âŒ Ollama connection failed: {e}")
        print("Make sure Ollama is running with: ollama serve")
        print("And that qwen3:latest is pulled: ollama pull qwen3:latest")
        return
    
    # Run the meetings
    eat_meeting = EnterpriseScaledAgileMeeting("eat")
    await eat_meeting.run_executive_action_team()
    
    ems_meeting = EnterpriseScaledAgileMeeting("ems") 
    await ems_meeting.run_executive_metascrum()
    
    sos_meeting = EnterpriseScaledAgileMeeting("sos")
    await sos_meeting.run_scrum_of_scrums()
    
    # Summary
    print("\n" + "="*60)
    print("ðŸ“Š MEETING SUMMARY")
    print("="*60)
    
    total_decisions = len(eat_meeting.decisions) + len(ems_meeting.decisions) + len(sos_meeting.decisions)
    total_actions = len(eat_meeting.action_items) + len(ems_meeting.action_items) + len(sos_meeting.action_items)
    
    print(f"\nâœ… Meetings Complete:")
    print(f"   Decisions made: {total_decisions}")
    print(f"   Action items: {total_actions}")
    print(f"\nðŸ¤– All decisions made by real LLM calls to Ollama")
    print(f"ðŸ“Š Structured output via Pydantic models")
    print(f"ðŸ“¡ Full observability through OTel spans")
    
    # Show mermaid diagram
    print("\n" + "="*60)
    print("ðŸ“ˆ COMMUNICATION FLOW")
    print("="*60)
    print("""
```mermaid
sequenceDiagram
    participant User
    participant CEO as CEO (Pydantic AI)
    participant CPO as CPO (Pydantic AI)
    participant SM as Scrum Master (Pydantic AI)
    participant Ollama as Ollama (qwen3)
    participant OTel as OpenTelemetry
    
    Note over CEO,OTel: Executive Action Team
    User->>CEO: Strategic investment decision
    CEO->>Ollama: Analyze $75M AI platform
    Ollama-->>CEO: StrategicDecision model
    CEO->>OTel: Span: decision + confidence + reasoning
    
    Note over CPO,OTel: Executive MetaScrum
    User->>CPO: Prioritize backlog
    CPO->>Ollama: WSJF analysis of features
    Ollama-->>CPO: BacklogPrioritization model
    CPO->>OTel: Span: priorities + scores + dependencies
    
    Note over SM,OTel: Scrum of Scrums
    User->>SM: Resolve impediment
    SM->>Ollama: Root cause analysis
    Ollama-->>SM: ImpedimentResolution model
    SM->>OTel: Span: resolution + escalation + prevention
    
    Note over OTel: All structured data in spans
```
""")

if __name__ == "__main__":
    print("ðŸš€ Starting REAL Pydantic AI Enterprise System")
    print("âš¡ This makes actual LLM calls with structured output")
    print("="*60)
    
    asyncio.run(run_real_enterprise_sas())